# Session 14: Diagonal Gait Reward Breakthrough

**Date**: 2025-12-23 evening to 2025-12-24 ~00:30
**Duration**: ~3 hours
**Experiments**: EXP-055, EXP-056, EXP-058

## Goal
Implement and test contact-based diagonal gait reward to break the standing local optimum.

## Key Achievement
**BREAKTHROUGH**: Forward-gated diagonal gait reward achieved vx=0.036 m/s (24% improvement over baseline 0.029)

## Technical Implementation

Added to `harold_isaac_lab_env.py`:
- Diagonal pair tracking: FL+BR (pair 0) vs FR+BL (pair 1)
- Switch detection: Reward when alternating between valid diagonal pairs
- Forward gating: `sigmoid(vx * 20.0)` biases stepping toward forward motion

```python
forward_gate = torch.sigmoid(vx * 20.0)
diagonal_gait_reward = weight * valid_switch.float() * forward_gate * upright_sq
```

## Experiments

| EXP | Config | Final vx | Peak vx | Verdict |
|-----|--------|----------|---------|---------|
| 055 | Ungated gait (5.0) | +0.022 | - | Worse - backward stepping |
| **056** | **Forward-gated (5.0)** | **+0.036** | - | **BEST - 24% improvement** |
| 058 | Forward-gated (10.0) | +0.018 | +0.061 | Regressed from peak |

## Key Findings

1. **Diagonal gait reward works**: First approach to beat baseline
2. **Forward gating essential**: Ungated led to backward stepping
3. **Higher weight = higher peak, more regression**: weight=10 peaked at vx=0.061 (61% of target!) but regressed
4. **Mid-training regression pattern**: Peak at 40-70%, then regression continues

## Configuration Changes

- Added `diagonal_gait_reward: 5.0` to RewardsCfg (forward-gated)
- Increased video frequency: interval 6400 â†’ 3200 steps

## Files Modified

- `harold_isaac_lab_env.py`: Added diagonal gait reward implementation
- `harold_isaac_lab_env_cfg.py`: Added diagonal_gait_reward config parameter
- `scripts/harold.py`: Reduced video_interval to 3200

## Memory Files Updated

- EXPERIMENTS.md: Added Session 14 documentation
- CONTEXT.md: Updated current state and best config
- NEXT_STEPS.md: Updated priorities (early stopping is now Priority 1)
- OBSERVATIONS.md: Added detailed Session 14 analysis

## Next Session Priorities

1. **Early stopping**: Stop training at peak performance (40-50%)
2. **Gait reward curriculum**: Decay gait weight as velocity increases
3. **Reference motion**: Use designed walking trajectories

## Summary

The diagonal gait reward successfully breaks the standing optimum by creating a direct gradient for stepping motion. Forward gating is essential to bias stepping toward forward direction. The robot CAN achieve vx=0.061 m/s (61% of target) but the policy regresses during continued training. Next focus should be on preventing mid-training regression through early stopping or curriculum.
